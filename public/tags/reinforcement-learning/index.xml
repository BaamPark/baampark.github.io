<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Reinforcement Learning on Baam&#39;s Techlog</title>
    <link>https://baampark.github.io/tags/reinforcement-learning/</link>
    <description>Recent content in Reinforcement Learning on Baam&#39;s Techlog</description>
    <generator>Hugo -- 0.122.0</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 23 Feb 2025 15:04:51 -0500</lastBuildDate>
    <atom:link href="https://baampark.github.io/tags/reinforcement-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Mathmatical Foundation from Markov to Q-learning</title>
      <link>https://baampark.github.io/posts/2025-02-23_rl_math/</link>
      <pubDate>Sun, 23 Feb 2025 15:04:51 -0500</pubDate>
      <guid>https://baampark.github.io/posts/2025-02-23_rl_math/</guid>
      <description>1. Markov Property The Markov Property is a fundamental concept in probability theory that states that the future state of a process depends only on its current state and not on the sequence of events that preceded it.
1.1. Markov Process A Markov process (markov chain) is a special type of random process that satisfies the Markov property. The Markov property states that the future state of the process depends only on the current state and not on any previous states.</description>
    </item>
  </channel>
</rss>
