<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Baam&#39;s Techlog</title>
    <link>https://baampark.github.io/</link>
    <description>Recent content on Baam&#39;s Techlog</description>
    <generator>Hugo -- 0.122.0</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 04 Oct 2025 15:32:28 -0400</lastBuildDate>
    <atom:link href="https://baampark.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>From Policy Gradient to GRPO: Policy Optimization for LLM Training</title>
      <link>https://baampark.github.io/posts/2025-10-04_rl_policy_optimization/</link>
      <pubDate>Sat, 04 Oct 2025 15:32:28 -0400</pubDate>
      <guid>https://baampark.github.io/posts/2025-10-04_rl_policy_optimization/</guid>
      <description>You’ve probably heard that DeepSeek R1 was fine-tuned using reinforcement learning, specifically an algorithm called Generalized Reparameterized Policy Optimization (GRPO). DeepSeek research team demostrated that reinforcement learning (RL) without any supervised fine-tuning can teach LLMs to reason, and this drew widespread interest and scrutiny across academia. In my previous blog post, Mathmatical Foundation from Markov to Deep Q-learning, we dabbled in Q-learning, which is value-based (off-policy) RL where the agent learns value (\(Q\) or \(V\)) and derives its policy \(\pi\) from the value.</description>
    </item>
    <item>
      <title>Why and When to Add New Special Tokens in LLMs and VLMs</title>
      <link>https://baampark.github.io/posts/2025-07-08_special_token/</link>
      <pubDate>Tue, 08 Jul 2025 21:40:50 -0400</pubDate>
      <guid>https://baampark.github.io/posts/2025-07-08_special_token/</guid>
      <description>A tokenizer converts natural language into a sequence of tokens. Among these tokens are special tokens, which are not regular words but serve specific functions for the model (e.g., &amp;lt;BOS&amp;gt; and &amp;lt;EOS&amp;gt;). While reviewing academic literature on LLMs and VLMs, I came across several studies that introduce new special tokens to enhance model capabilities. In this blog, we’ll explore what special tokens are in LLM tokenization and, more importantly, examine when and why researchers choose to add new special tokens.</description>
    </item>
    <item>
      <title>LLM Decoding: Inference in Autoregressive Language Models</title>
      <link>https://baampark.github.io/posts/2025-06-03_llm_decoding/</link>
      <pubDate>Tue, 03 Jun 2025 15:28:55 -0400</pubDate>
      <guid>https://baampark.github.io/posts/2025-06-03_llm_decoding/</guid>
      <description>Most large language models (LLMs) today are autoregressive models. Before LLMs, NLP was fragmented — different problems like text classification, translation, summarization, and question answering all needed their own models, datasets, and training tricks. But then came GPT-2, and everything changed. GPT-2 is an autoregressive model trained purely on text generation — predicting the next word in a sequence — that’s called decoding.Surprisingly, this simple setup made it capable of handling a wide range of NLP tasks, often without fine-tuning.</description>
    </item>
    <item>
      <title>Smoothed Particle Hydrodynamics Simulation with CUDA</title>
      <link>https://baampark.github.io/posts/2025-04-06_sph/</link>
      <pubDate>Sun, 06 Apr 2025 15:04:51 -0500</pubDate>
      <guid>https://baampark.github.io/posts/2025-04-06_sph/</guid>
      <description>In this blog post, I will share my journey with my final project for my computer graphics course at school. Computer graphics is used to generate images, animations, and visual effects. You might see mechanical engineering students doing CAD (Computer-Aided Design) work — that’s also a form of computer graphics, though it focuses more on precision modeling and simulation for physical systems. OpenGL is is an API for rendering 2D and 3D vector graphics, commonly used by engineers and architects for CAD behind the hood.</description>
    </item>
    <item>
      <title>Mathmatical Foundation from Markov to Deep Q-learning</title>
      <link>https://baampark.github.io/posts/2025-02-23_rl_math/</link>
      <pubDate>Sun, 23 Feb 2025 15:04:51 -0500</pubDate>
      <guid>https://baampark.github.io/posts/2025-02-23_rl_math/</guid>
      <description>When I first started studying reinforcement learning, I was intimidated by the amount of mathematical background required to understand even the basic concepts. Terms like “Markov property,” “Bellman equation,” and “Q-learning” felt abstract and overwhelming. In this blog post, we will walk through these foundations step by step, starting from probability basics and building up toward deep reinforcement learning. Specifically, we will cover: 1) Markov decision process (MDP) 2) Value function, 3) Q-learning, and 4) Deep Q-learning (DQN).</description>
    </item>
    <item>
      <title>Segment Anything 2 vs. SAM1: What’s New and Why It Matters</title>
      <link>https://baampark.github.io/posts/2025-02-06_sam2/</link>
      <pubDate>Thu, 06 Feb 2025 12:19:07 -0500</pubDate>
      <guid>https://baampark.github.io/posts/2025-02-06_sam2/</guid>
      <description>In my last post, we explored how Segment Anything (SAM) works in image segmentation, breaking down the key components of its model architecture. SAM achieved great success in image segmentation, demonstrating two key strengths: its foundation as a large-scale model trained on an extensive dataset and its ability to be promptable, allowing users to generate segmentations with flexible inputs. These two strengths allow SAM to deliver impressive performance in a zero-shot setting.</description>
    </item>
    <item>
      <title>Segment Anything, the first large-scale foundation model for segmentation</title>
      <link>https://baampark.github.io/posts/2025-01-29_sam/</link>
      <pubDate>Wed, 29 Jan 2025 13:49:47 -0500</pubDate>
      <guid>https://baampark.github.io/posts/2025-01-29_sam/</guid>
      <description>Segment Anything (SAM) has drawn massive attention in the computer vision community, accumulating an impressive 8,000 citations. Segmentation has long been a crucial yet challenging aspect of computer vision. One of the biggest hurdles? Annotation. Unlike simple bounding boxes, which only require marking the object’s general location, segmentation demands precise pixel-level annotations—an incredibly tedious and time-consuming task for annotators. SAM is one of the first large-scale foundation models for segmentation.</description>
    </item>
    <item>
      <title>How Transformers Handle Variable-length Sequnces</title>
      <link>https://baampark.github.io/posts/2025-01-28_variable_sequence/</link>
      <pubDate>Mon, 27 Jan 2025 13:49:47 -0500</pubDate>
      <guid>https://baampark.github.io/posts/2025-01-28_variable_sequence/</guid>
      <description>&amp;ldquo;Transformer models don&amp;rsquo;t require a fixed sequence length.&amp;rdquo; Since most of my projects revolve around computer vision, this was very confusing to me. In computer vision models, images are always preprocessed to a fixed size before being fed into deep learning models. Otherwise, you will encounter matrix multiplication error. In this post, we will learn how transofrmer handles variable-length sequnces.
Self-attention - Q, K, V Linear Projection into Embedding Space Let&amp;rsquo;s see basic CNN code example.</description>
    </item>
    <item>
      <title>The Power of Graph Representation Learning in Modern Computer Vision</title>
      <link>https://baampark.github.io/posts/2024-07-25_gcn/</link>
      <pubDate>Thu, 25 Jul 2024 10:02:46 -0400</pubDate>
      <guid>https://baampark.github.io/posts/2024-07-25_gcn/</guid>
      <description>Graph structures have been applied in many scientific fields, such as biology, computer science, and social network analysis. With the increasing popularity of machine learning, the graph representation learning (GRL) paradigm has emerged as effective methods. One example is the Graph Convolutional Network (GCN), which has shown remarkable success in tasks like node classification, graph generation and clustering by effectively capturing the complex relationships in graph data. GRL is also making big waves in modern computer vision.</description>
    </item>
    <item>
      <title>Low Rank Adaptation</title>
      <link>https://baampark.github.io/posts/2024-07-18_lora/</link>
      <pubDate>Thu, 18 Jul 2024 04:05:02 -0400</pubDate>
      <guid>https://baampark.github.io/posts/2024-07-18_lora/</guid>
      <description>Why Low Rank Adaptation Matters: A Closer Look at Its Impact on Machine Learning Low Rank Adaptation (LoRA) is a fine-tuning technique designed to efficiently update and adapt large pre-trained models, such as language or diffusion models, without retraining them entirely. Low Rank Adaptation was proposed in 2021 by Edward Hu et al. They demonstrated that LoRA significantly reduces the number of trainable parameters and GPU memory requirements. But how is that possible?</description>
    </item>
  </channel>
</rss>
