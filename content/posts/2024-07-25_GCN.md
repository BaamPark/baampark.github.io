---
title: 'The Power of Graph Representation Learning in Modern Computer Vision'
date: '2024-07-25T10:02:46-04:00'
draft: false
params:
  math: true
tags: [Graph Learning]
---

![Cover Image](/images/2024-07-25_GCN/cover.png)
Graph structures have been applied in many scientific fields, such as biology, computer science, and social network analysis. With the increasing popularity of machine learning, the graph representation learning (GRL) paradigm has emerged as effective methods. One example is the Graph Convolutional Network (GCN), which has shown remarkable success in tasks like node classification, graph generation and clustering by effectively capturing the complex relationships in graph data. GRL is also making big waves in modern computer vision. 

You might wonder how GRL can be used in modern computer vision. The potential of graphs isn't just about finding paths from point A to point B. For instance, you can restructure an image into a graph, transforming pixels into nodes and their relationships into edges. That's not it. You can even restructure a complex label for an image into a graph and use it for graph learning. In this article, we will talk about how graph representation learning can be used in modern computer vision. We will also cover a pratice of graph representation learning using Pytorch. 

## Graph Theory and Terminology
Mathematically, a graph is a pair \(G = (V ,E)\) where \(V\) is a set of vertices and \(E\) is a set of ordered pairs of vertices called edges. In a weighted graph, graph can be represented \(G = (V ,E, W)\) where \(W\) is a adjecency matrix, \(W \in \mathbb{R}^{n \times n}\). \(W_{ij}=0\), if there is no edge between vertices \(i\) and \(j\). In some graph theory books, \(W_{ij} = \infty \) when there is no edge between vertices \(i\) and \(j\). However, in this article, we will stick to the former definition. 

### Adjacency Matrix
There are many representations for graph strucuters such as Adjacency Matrix, Adjacency Matrix, and Edge List, and Compressed Sparse Row. In this article, we only cover Adjacency Matrix. See an example in the below image to understand how weighted directed graph can be represented in Adjacency Matrix.
![Adjacency Matrix](/images/2024-07-25_GCN/adjscency_matrix.png)

## Image to Graph
We learned mathemtical background of graph theory. But still you might not clear how graph can be applied to computer vision i.e., image to graph. Let's recall what a neural network does. Simply put, a neural network can be viewed as an encoder that maps data to low dimensional representation for further tasks. So the encoder will function if the data is represented in a vector space.

The question is how we represent image to graph?

<!-- Writing is in progress -->
<!-- ## Application of Graph Representation Learning
The 
### Person Attribute Recognition -->
<!-- Visual-Semantic Graph Reasoning for Pedestrian Attribute Recognition -->

## Reference
- Graph Representation Learning Meets Computer Vision: A Survey